% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/my_aaply.R
\name{my_aaply}
\alias{my_aaply}
\title{Temporary local version of 'aaply'}
\usage{
my_aaply(.arg_grid, .fun, .new_dnn = "values", .new_dn = NULL, ...)
}
\arguments{
\item{.arg_grid}{A data-frame, typically created by
\code{expand.grid} used on a list containing references to the
dimension names of some array containing values which we want
\code{.fun} to work upon.}

\item{.fun}{The function that we want to use. The first argument of
\code{.fun} must be able to digest a row from the data-frame
\code{.arg_grid}.}

\item{.new_dnn}{The name to be used on the dimension of the result
that originates from \code{.fun}.}

\item{.new_dn}{A vector to be used upon the result that originates
from \code{.fun}.  The default value \code{NULL} will trigger
the use of the names returned by \code{.fun}.  The main
intention of this function is to add a name when the result has
length one and no names.}

\item{...}{Arguments to be given to \code{.fun}.}
}
\value{
For functions that return a vector of values, the returned
    object will be similar to the result obtained by
    \code{plyr::aaply}, with the difference that the new dimension
    will be named "values".
}
\description{
The 'aaply' function did for some reason not want to cooperate for
one of the cases I needed to investigate, so an ad-hoc solution had
to be created in order to get a work-around.  The result of this
function has been sanity-checked with the result from 'aaply' for
one of the cases where 'plyr::aaply' did work.  Note that even
though the order of the dimensions are ensured to be the same, the
internal order in some of the dimensions might differ, so use
\code{restrict_array} to permute them into the same order.
}
\details{
Note that the result from functions that returns matrices/arrays
probably will look like shit if used in this first coarse
approximation.  It might be possible to create a more advanced
version of this function by using 'abind' instead of 'rbind' in the
construction, but as I at the moment don't need such funcitonality,
I will simply ignore it for the time being.

It might perhaps be possible to adjust this function in order to do
bigger chunks when sending stuff to the available cores, which
might reduce the overhead a bit.  But this will require another
design of the function, which I can't use time on.
}

